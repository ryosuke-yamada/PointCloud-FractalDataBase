

<!DOCTYPE html>
<html>
<head>
	<title>Point Cloud Pre-training with Natural 3D Structures</title>
    <link rel="stylesheet" type="text/css" href="./pvg.css">
    <link rel="shortcut icon" type="image/png" href="./img/cc_logo_1_crop.png">
    <!--<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">-->
</head>

<body>
<script type="text/javascript" src="./header.js"></script>

<style>
a.myclass {
    color:#DE382D;
    text-decoration: underline
}
</style>

<style>
a.link {
    text-decoration: underline
}
</style>


<h1 align="center" style="font-size: 30pt;"><b>Point Cloud Pre-training with <br> Natural 3D Structures</b></h1><br/>

<center>
    <a href="https://twitter.com/FragileGoodwill" class="">Ryosuke Yamada</a><sup>1</sup> &emsp; <a href="http://hirokatsukataoka.net/" class="">Hirokatsu Kataoka</a><sup>1</sup> &emsp; <a href="" class="">Naoya Chiba</a><sup>2</sup> &emsp; Yasuyuki Domae<sup>1</sup> &emsp; Tetsuya Ogata<sup></sup><br>
    1: AIST &emsp; 2: Waseda Universsity <br><br>

    <section class="delta">
        <div class="container">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.pdf"><button class="btn btn-gray">Paper (CVPR 2022)</button></a>
            <a href="https://github.com/ryosuke-yamada/3dfractaldb"><button class="btn btn-gray">code</button></a>            
            <a href="#dataset"><button class="btn btn-gray">Dataset</button></a> <br>
            <a href=""><button class="btn btn-gray">Poster</button></a>
            <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yamada_Point_Cloud_Pre-Training_CVPR_2022_supplemental.pdfs"><button class="btn btn-gray">Supp</button></a>
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.pdf"><button class="btn btn-gray">Related Work</button></a>
        </div>
    </section>
    <br><br>
    <iframe width="800" height="450" src="https://youtu.be/lv8nvrMOedo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <!--<img src="./img/teaser.png" style="width: 100%;"/>-->
</center>

<br>
<h2>Abstract</h2>
<p>
    The construction of 3D point cloud datasets requires a great deal of human effort. Therefore, constructing a large-scale 3D point clouds dataset is difficult. 
    In order to remedy this issue, we propose a newly developed point cloud fractal database (PC-FractalDB), which is a novel family of formula-driven supervised learning inspired by fractal geometry encountered in natural 3D structures. 
    Our research is based on the hypothesis that we could learn representations from more real-world 3D patterns than conventional 3D datasets by learning fractal geometry. 
    We show how the PC-FractalDB facilitates solving several recent dataset-related problems in 3D scene understanding, such as 3D model collection and labor-intensive annotation. 
    The experimental section shows how we achieved the performance rate of up to 61.9% and 59.4% for the ScanNetV2 and SUN RGB-D datasets, respectively, over the current highest scores obtained with the PointContrast,  contrastive scene contexts (CSC), and RandomRooms. 
    Moreover, the PC-FractalDB pre-trained model is especially effective in training with limited data. For example, in 10\% of training data on ScanNetV2, the PC-FractalDB pre-trained VoteNet performs at 38.3%, which is +14.8% higher accuracy than CSC. 
    Of particular note, we found that the proposed method achieves the highest results for 3D object detection pre-training in limited point cloud data.
</p>

<br>
<h2>Framework</h2>
Overview of the formula-driven supervised learning framework for 3D object detection with 3D point clouds. 
We generate a 3D fractal model using the 3D iterated function system. 
The proposed PC-FractalDB is automatically constructed by difiniting a fractal category using variance threshold and instance augmentation with FractalNoiseMix. 
A 3D fractal scene is generated by randomly selecting 3D fractal models and translating these from the origin on the z-plane. 
<br><br><br>
<center>
        <img src="./img/overview.png" style="width: 100%;"/>
</center>

<br><br><br>
<h2>Experimental Results</h2>
3D object detection comparisons on representative datasets. 
We employed architecture with the basic VoteNet model and used them to compare network pre-training methods, including training from scratch, PointContrast, CSC, RandomRooms, and the PC-FractalDB. 
<br><br><br>
<center>
        <img src="./img/results1.png" style="width: 85%;"/>
</center>


<br><br><br>
<h2>Additional Results</h2>
The PC-FractalDB pre-train can acquire effective features compared to previous self-supervised learning methods for limited data on fine-tuning datasets.
<br><br><br>
<center>
        <img src="./img/results2.png" style="width: 85%;"/>
</center>

<br>
<h2>Citation</h2>

<br><br>


<a name="dataset"><h2>Dataset Download</h2></a>
<ul>
    <li>
        PC-FractalDB-1k (1k categories x 500 instances; Total 500k models).
        <a href="">[Dataset (**GB)]</a>
    </li>
</ul>
<br><br>

<h2>Acknowledgement</h2></a>
<ul>
    <li> This work is based on results obtained from a project, JPNP20006, commissioned by the New Energy and Industrial Technology Development Organization (NEDO).</li>
    <li> Computational resource of AI Bridging Cloud Infrastructure (ABCI) provided by National Institute of Advanced Industrial Science and Technology (AIST) was used.</li>
</ul>

<script type="text/javascript" src="./footer.js"></script>
</body></html>
